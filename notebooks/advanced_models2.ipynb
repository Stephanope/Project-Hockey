{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7188cdf-cdac-4107-8a75-3ff228b2d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from ift6758.data import load_cached_season_dataframe, load_cached_seasons_dataframe, new_variables, goal_rate_by_percentile\n",
    "from ift6758.data.graphs import plot_goal_curve\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, StratifiedKFold, RandomizedSearchCV, StratifiedGroupKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56021794-b124-4250-a586-07617402737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = load_cached_seasons_dataframe(2016,2019) \n",
    "df_test = load_cached_season_dataframe(2020) # on y touche pas jusqu'à la fin\n",
    "df = new_variables(df_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8dc4a-c415-43b2-bbba-a95204782905",
   "metadata": {},
   "source": [
    "## Séparation des données d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9ea3ea-483e-44e1-98b9-45d7c1a2d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode pour typeShot et lastEvent\n",
    "cat_cols = [c for c in [\"typeShot\", \"lastEvent\", \"goalStrenght\"] if c in df.columns]\n",
    "if cat_cols:\n",
    "    df = pd.get_dummies(df, columns=cat_cols, dummy_na=True)\n",
    "\n",
    "# transforme les inf en NaN\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Filtrer les NaN \n",
    "mask_tr = df.notna().all(axis=1)\n",
    "\n",
    "df = df[mask_tr]\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "\n",
    "train_idxs, val_idxs = next(splitter.split(df, groups=df['gameId']))\n",
    "df_train = df.iloc[train_idxs].copy()\n",
    "df_val = df.iloc[val_idxs].copy()\n",
    "\n",
    "X_train = df_train.drop(columns=[\"isGoal\",\"timeInPeriod\",\"typeEvent\", \"shooter\",\"goalie\", \"teamShot\"])\n",
    "X_val   = df_val.drop(columns=[\"isGoal\",\"timeInPeriod\",\"typeEvent\", \"shooter\",\"goalie\", \"teamShot\"])\n",
    "\n",
    "y_train = df_train[\"isGoal\"].astype(int)\n",
    "y_val = df_val[\"isGoal\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372a4c8-0f01-4968-a992-9340596f7570",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd329e7-65e1-4642-b535-494aa4ee0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: stefan-sucatu (stefan-sucatu-polytechnique-montr-al) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\stefa\\OneDrive\\Desktop\\Stefan\\Hockey\\Project-Hockey\\notebooks\\wandb\\run-20260128_123750-hjtin8g8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/hjtin8g8' target=\"_blank\">random-forest</a></strong> to <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/hjtin8g8' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/hjtin8g8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9106942388103412\n",
      "AUC: 0.7583785894948027\n",
      "Log Loss: 0.27224530759332766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: \n",
      "wandb: Plotting Random Forest.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "wandb: Logged feature importances.\n",
      "wandb: Logged confusion matrix.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "wandb: Logged summary metrics.\n",
      "wandb: Logged class proportions.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "wandb: Logged calibration curve.\n",
      "wandb: WARNING wandb uses only 10000 data points to create the plots.\n",
      "wandb: Logged roc curve.\n",
      "wandb: Logged precision-recall curve.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>log_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.91069</td></tr><tr><td>auc</td><td>0.75838</td></tr><tr><td>log_loss</td><td>0.27225</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">random-forest</strong> at: <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/hjtin8g8' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/hjtin8g8</a><br> View project at: <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai</a><br>Synced 5 W&B file(s), 7 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260128_123750-hjtin8g8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"projet-hockey-ai\", \n",
    "    name=\"random-forest\",\n",
    "    tags=[\"all-features\", \"random-forest\"],\n",
    "    save_code=True\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "y_proba_rf = rf.predict_proba(X_val)\n",
    "\n",
    "# 6. Calcul des métriques\n",
    "acc_rf = accuracy_score(y_val, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_val, y_proba_rf[:, 1])\n",
    "ll_rf = log_loss(y_val, y_proba_rf[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {acc_rf}\")\n",
    "print(f\"AUC: {auc_rf}\")\n",
    "print(f\"Log Loss: {ll_rf}\")\n",
    "\n",
    "# Logging automatique des courbes dans WandB\n",
    "# WandB crée automatiquement la courbe ROC, la matrice de confusion et la courbe de précision-rappel\n",
    "wandb.sklearn.plot_classifier(\n",
    "    rf, X_train, X_val, y_train, y_val,\n",
    "    y_pred_rf, y_proba_rf, \n",
    "    labels=['Non-Goal', 'Goal'], \n",
    "    model_name='Random Forest', \n",
    "    feature_names=list(X_train.columns)\n",
    ")\n",
    "\n",
    "wandb.log({\"accuracy\": acc_rf, \"auc\": auc_rf, \"log_loss\": ll_rf})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d1f6b-408a-4ae3-ba4e-74036588ad53",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64b75ab-ab0e-4654-ac9b-b69043ef0729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-28 12:38:51,218] A new study created in memory with name: no-name-a22d1036-9ae9-4e9d-8497-c04f470bd485\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:40:08,667] Trial 0 finished with value: -0.5901151809129019 and parameters: {'k': 20, 'n_estimators': 500, 'max_depth': 9, 'min_samples_split': 18, 'min_samples_leaf': 9, 'max_features': 'log2', 'class_weight': 'balanced_subsample', 'min_impurity_decrease': 0.00042545693234134877}. Best is trial 0 with value: -0.5901151809129019.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:41:24,250] Trial 1 finished with value: -0.5844009797544004 and parameters: {'k': 10, 'n_estimators': 900, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'log2', 'class_weight': 'balanced', 'min_impurity_decrease': 0.00013899377181588523}. Best is trial 1 with value: -0.5844009797544004.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:44:21,259] Trial 2 finished with value: -0.5786910045680721 and parameters: {'k': 52, 'n_estimators': 500, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 0.5, 'class_weight': 'balanced_subsample', 'min_impurity_decrease': 0.0005794401201565758}. Best is trial 2 with value: -0.5786910045680721.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:45:02,514] Trial 3 finished with value: -0.5899603776279674 and parameters: {'k': 11, 'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'class_weight': 'balanced_subsample', 'min_impurity_decrease': 0.0005446141952876134}. Best is trial 2 with value: -0.5786910045680721.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:47:17,882] Trial 4 finished with value: -0.5351476026933843 and parameters: {'k': 36, 'n_estimators': 600, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 0.3, 'class_weight': 'balanced', 'min_impurity_decrease': 5.994916808641171e-06}. Best is trial 4 with value: -0.5351476026933843.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:49:23,597] Trial 5 finished with value: -0.584345509303208 and parameters: {'k': 23, 'n_estimators': 700, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 0.5, 'class_weight': 'balanced', 'min_impurity_decrease': 0.0007709088675162581}. Best is trial 4 with value: -0.5351476026933843.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:52:18,648] Trial 6 finished with value: -0.5927263424412988 and parameters: {'k': 18, 'n_estimators': 1000, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2', 'class_weight': 'balanced_subsample', 'min_impurity_decrease': 0.0007852848255945161}. Best is trial 4 with value: -0.5351476026933843.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:52:51,478] Trial 7 finished with value: -0.2721641211458726 and parameters: {'k': 17, 'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 3, 'max_features': 0.3, 'class_weight': None, 'min_impurity_decrease': 0.00015356681086517543}. Best is trial 7 with value: -0.2721641211458726.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 12:59:28,913] Trial 8 finished with value: -0.5781951095465356 and parameters: {'k': 52, 'n_estimators': 1000, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': 0.5, 'class_weight': 'balanced', 'min_impurity_decrease': 0.0006240417731975798}. Best is trial 7 with value: -0.2721641211458726.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:00:54,559] Trial 9 finished with value: -0.5721824223026083 and parameters: {'k': 28, 'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 0.3, 'class_weight': 'balanced_subsample', 'min_impurity_decrease': 0.00021513216614935183}. Best is trial 7 with value: -0.2721641211458726.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:01:29,585] Trial 10 finished with value: -0.2735648600377754 and parameters: {'k': 38, 'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 0.3, 'class_weight': None, 'min_impurity_decrease': 0.0003264565169699725}. Best is trial 7 with value: -0.2721641211458726.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:02:03,159] Trial 11 finished with value: -0.2734417973294545 and parameters: {'k': 38, 'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 0.3, 'class_weight': None, 'min_impurity_decrease': 0.0003191439461616622}. Best is trial 7 with value: -0.2721641211458726.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:02:38,707] Trial 12 finished with value: -0.2730443227947898 and parameters: {'k': 42, 'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 0.3, 'class_weight': None, 'min_impurity_decrease': 0.00027879105755320815}. Best is trial 7 with value: -0.2721641211458726.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:05:31,883] Trial 13 finished with value: -0.2616652521752987 and parameters: {'k': 47, 'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.3, 'class_weight': None, 'min_impurity_decrease': 6.338129671633395e-06}. Best is trial 13 with value: -0.2616652521752987.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:06:27,765] Trial 14 finished with value: -0.2685186050905757 and parameters: {'k': 30, 'n_estimators': 400, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': None, 'min_impurity_decrease': 2.8367457526379285e-05}. Best is trial 13 with value: -0.2616652521752987.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:08:10,628] Trial 15 finished with value: -0.2647093952079745 and parameters: {'k': 45, 'n_estimators': 500, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': None, 'min_impurity_decrease': 1.0292344074254305e-05}. Best is trial 13 with value: -0.2616652521752987.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:08:59,688] Trial 16 finished with value: -0.2874143807764046 and parameters: {'k': 45, 'n_estimators': 700, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': None, 'min_impurity_decrease': 0.0009840956541617544}. Best is trial 13 with value: -0.2616652521752987.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:09:58,972] Trial 17 finished with value: -0.272705315055733 and parameters: {'k': 46, 'n_estimators': 500, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'class_weight': None, 'min_impurity_decrease': 8.189111029551674e-05}. Best is trial 13 with value: -0.2616652521752987.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:10:56,176] Trial 18 finished with value: -0.2807634673512884 and parameters: {'k': 46, 'n_estimators': 700, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'class_weight': None, 'min_impurity_decrease': 0.0004241504362360246}. Best is trial 13 with value: -0.2616652521752987.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "[I 2026-01-28 13:11:32,319] Trial 19 finished with value: -0.27811417893728374 and parameters: {'k': 35, 'n_estimators': 400, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': None, 'min_impurity_decrease': 0.0001992950294706843}. Best is trial 13 with value: -0.2616652521752987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés :\n",
      "{'k': 47, 'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.3, 'class_weight': None, 'min_impurity_decrease': 6.338129671633395e-06}\n",
      "Meilleur score (neg_log_loss) : -0.2616652521752987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [34 36 42 43 45 47 51] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features finales retenues (47) : ['gameSeconds', 'period', 'eventId', 'x', 'y', 'openNet', 'lastEventX', 'lastEventY', 'timeSinceLastEvent', 'distanceSinceLastEvent', 'friendlySkaters', 'opposingSkaters', 'timeInPowerPlay', 'gameId', 'season', 'gameType', 'attack_sign', 'x_adj', 'y_adj', 'shotDistance', 'shotAngle', 'isEmpty', 'isRebound', 'angleDifference', 'speed', 'typeShot_backhand', 'typeShot_deflected', 'typeShot_slap', 'typeShot_snap', 'typeShot_tip-in', 'typeShot_wrap-around', 'typeShot_wrist', 'typeShot_nan', 'lastEvent_blocked-shot', 'lastEvent_faceoff', 'lastEvent_giveaway', 'lastEvent_goal', 'lastEvent_hit', 'lastEvent_missed-shot', 'lastEvent_penalty', 'lastEvent_shot-on-goal', 'lastEvent_takeaway', 'lastEvent_nan', 'goalStrenght_EV', 'goalStrenght_PP', 'goalStrenght_SH', 'goalStrenght_nan']\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "groups = df_train[\"gameId\"]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    max_cols = X_train.shape[1]\n",
    "    k_value = trial.suggest_int('k', 10, max_cols)\n",
    "\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', [\"sqrt\", \"log2\", 0.3, 0.5]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, \"balanced\", \"balanced_subsample\"]),\n",
    "        'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 1e-3),\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('selection', SelectKBest(score_func=f_classif, k=k_value)),\n",
    "        ('clf', RandomForestClassifier(**rf_params, bootstrap=True, random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipeline, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        groups=groups, \n",
    "        cv=cv, \n",
    "        scoring=\"neg_log_loss\",\n",
    "        n_jobs=1 \n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Meilleurs paramètres trouvés :\")\n",
    "print(study.best_params)\n",
    "print(f\"Meilleur score (neg_log_loss) : {study.best_value}\")\n",
    "\n",
    "# 1. On sépare le paramètre 'k' des paramètres du Random Forest\n",
    "best_params = study.best_params.copy()\n",
    "best_k = best_params.pop('k') # On extrait k et on l'enlève du dictionnaire\n",
    "\n",
    "# 2. On reconstruit le pipeline gagnant\n",
    "final_pipeline = Pipeline([\n",
    "    ('selection', SelectKBest(score_func=f_classif, k=best_k)),\n",
    "    ('clf', RandomForestClassifier(**best_params, bootstrap=True, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 3. On entraîne sur tout le dataset d'entraînement\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Si tu veux voir quelles colonnes ont été choisies au final :\n",
    "selected_mask = final_pipeline.named_steps['selection'].get_support()\n",
    "selected_features = X_train.columns[selected_mask]\n",
    "print(f\"Features finales retenues ({len(selected_features)}) :\", list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c47c7-d195-4afe-87a7-ca2e7ccadd05",
   "metadata": {},
   "source": [
    "# Neural Networks (Multilayer Percetron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2a1058-320d-4aec-a1f6-77edbcd436ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_baseline = X_train.copy()\n",
    "X_val_baseline = X_val.copy()\n",
    "\n",
    "scaler_baseline = StandardScaler()\n",
    "X_train_scaled = scaler_baseline.fit_transform(X_train_baseline)\n",
    "X_val_scaled = scaler_baseline.transform(X_val_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4febcfbb-049f-44f9-8173-58bd62e9423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP-Baseline</strong> at: <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/6p0nznn3' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/6p0nznn3</a><br> View project at: <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260128_133748-6p0nznn3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\stefa\\OneDrive\\Desktop\\Stefan\\Hockey\\Project-Hockey\\notebooks\\wandb\\run-20260128_133834-lrodfxlx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/lrodfxlx' target=\"_blank\">MLP-Baseline</a></strong> to <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/lrodfxlx' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/lrodfxlx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9107593186144509\n",
      "AUC: 0.7675296783944106\n",
      "Log Loss: 0.26636425940374936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: \n",
      "wandb: Plotting MLP Baseline.\n",
      "wandb: WARNING could not find any of attributes feature_importances_, feature_log_prob_, coef_ on classifier. Cannot plot feature importances.\n",
      "wandb: Logged feature importances.\n",
      "wandb: Logged confusion matrix.\n",
      "wandb: Logged summary metrics.\n",
      "wandb: Logged class proportions.\n",
      "wandb: Logged calibration curve.\n",
      "wandb: WARNING wandb uses only 10000 data points to create the plots.\n",
      "wandb: Logged roc curve.\n",
      "wandb: Logged precision-recall curve.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>auc</td><td>▁</td></tr><tr><td>log_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.91076</td></tr><tr><td>auc</td><td>0.76753</td></tr><tr><td>log_loss</td><td>0.26636</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP-Baseline</strong> at: <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/lrodfxlx' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai/runs/lrodfxlx</a><br> View project at: <a href='https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai' target=\"_blank\">https://wandb.ai/stefan-sucatu-polytechnique-montr-al/projet-hockey-ai</a><br>Synced 5 W&B file(s), 6 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260128_133834-lrodfxlx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"projet-hockey-ai\", \n",
    "    name=\"MLP-Baseline\",\n",
    "    tags=[\"all-features\", \"MLP\"],\n",
    "    save_code=True\n",
    ")\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50), \n",
    "    activation='relu',\n",
    "    solver='adam', \n",
    "    alpha=0.0001, \n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive', \n",
    "    max_iter=500, \n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# On entraîne sur la version scalée\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur la version scalée\n",
    "y_pred_mlp = mlp.predict(X_val_scaled)\n",
    "y_proba_mlp = mlp.predict_proba(X_val_scaled)\n",
    "\n",
    "acc_mlp = accuracy_score(y_val, y_pred_mlp)\n",
    "auc_mlp = roc_auc_score(y_val, y_proba_mlp[:, 1])\n",
    "ll_mlp = log_loss(y_val, y_proba_mlp[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {acc_mlp}\")\n",
    "print(f\"AUC: {auc_mlp}\")\n",
    "print(f\"Log Loss: {ll_mlp}\")\n",
    "\n",
    "wandb.sklearn.plot_classifier(\n",
    "    mlp, X_train_scaled, X_val_scaled, y_train, y_val, \n",
    "    y_pred_mlp, y_proba_mlp, \n",
    "    labels=['Non-Goal', 'Goal'], \n",
    "    model_name='MLP Baseline', \n",
    "    feature_names=list(X_train.columns) # On utilise X_train ici juste pour avoir les noms !\n",
    ")\n",
    "\n",
    "wandb.log({\"accuracy\": acc_mlp, \"auc\": auc_mlp, \"log_loss\": ll_mlp})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1dd0520-513a-497f-8b9d-32faae3a9434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-28 13:40:23,791] A new study created in memory with name: no-name-0118af8c-f98f-40b3-8a61-53e09f276255\n",
      "[I 2026-01-28 13:41:17,828] Trial 0 finished with value: -0.26621726133824536 and parameters: {'k': 40, 'hidden_layer_sizes': (100, 50), 'activation': 'relu', 'alpha': 0.07509144084336435, 'learning_rate_init': 0.0009115983463619342, 'batch_size': 128}. Best is trial 0 with value: -0.26621726133824536.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:41:44,276] Trial 1 finished with value: -0.2675607684273507 and parameters: {'k': 16, 'hidden_layer_sizes': (50, 25), 'activation': 'relu', 'alpha': 0.0803607356924783, 'learning_rate_init': 0.0009538436883425712, 'batch_size': 'auto'}. Best is trial 0 with value: -0.26621726133824536.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:42:56,510] Trial 2 finished with value: -0.26551227275608186 and parameters: {'k': 31, 'hidden_layer_sizes': (100, 50), 'activation': 'tanh', 'alpha': 5.296547086146484e-05, 'learning_rate_init': 0.0002418522160108974, 'batch_size': 'auto'}. Best is trial 2 with value: -0.26551227275608186.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:43:43,648] Trial 3 finished with value: -0.268061524107908 and parameters: {'k': 26, 'hidden_layer_sizes': (100, 50), 'activation': 'tanh', 'alpha': 0.06692688658458837, 'learning_rate_init': 0.005525771670808478, 'batch_size': 'auto'}. Best is trial 2 with value: -0.26551227275608186.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:44:42,609] Trial 4 finished with value: -0.266211334496759 and parameters: {'k': 24, 'hidden_layer_sizes': (50, 25), 'activation': 'relu', 'alpha': 0.001555122147492108, 'learning_rate_init': 0.00032079756506062465, 'batch_size': 64}. Best is trial 2 with value: -0.26551227275608186.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:46:58,566] Trial 5 finished with value: -0.26701083250481256 and parameters: {'k': 23, 'hidden_layer_sizes': (100, 50, 25), 'activation': 'relu', 'alpha': 5.748650313298576e-05, 'learning_rate_init': 0.00037062738026276073, 'batch_size': 64}. Best is trial 2 with value: -0.26551227275608186.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:48:37,632] Trial 6 finished with value: -0.26610652484047115 and parameters: {'k': 28, 'hidden_layer_sizes': (100, 50, 25), 'activation': 'tanh', 'alpha': 0.03896476513175892, 'learning_rate_init': 0.0005108375887532798, 'batch_size': 64}. Best is trial 2 with value: -0.26551227275608186.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=51 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=51 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=51 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2026-01-28 13:50:48,908] Trial 7 finished with value: -0.2655033890234065 and parameters: {'k': 51, 'hidden_layer_sizes': (50, 25), 'activation': 'tanh', 'alpha': 0.00032242116554719947, 'learning_rate_init': 0.0003965952271402941, 'batch_size': 32}. Best is trial 7 with value: -0.2655033890234065.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=46 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=46 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=46 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2026-01-28 13:51:20,401] Trial 8 finished with value: -0.2691000494894423 and parameters: {'k': 46, 'hidden_layer_sizes': (50,), 'activation': 'relu', 'alpha': 0.00011993880581774924, 'learning_rate_init': 0.0001574829678104258, 'batch_size': 'auto'}. Best is trial 7 with value: -0.2655033890234065.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:52:20,271] Trial 9 finished with value: -0.26552932151720804 and parameters: {'k': 30, 'hidden_layer_sizes': (50, 25), 'activation': 'relu', 'alpha': 0.008414888012851318, 'learning_rate_init': 0.0005012295449707731, 'batch_size': 64}. Best is trial 7 with value: -0.2655033890234065.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=51 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=51 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:782: UserWarning: k=51 is greater than n_features=45. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2026-01-28 13:54:38,599] Trial 10 finished with value: -0.2687646093576666 and parameters: {'k': 51, 'hidden_layer_sizes': (100,), 'activation': 'tanh', 'alpha': 1.1062706546891613e-05, 'learning_rate_init': 0.0032323002803356137, 'batch_size': 32}. Best is trial 7 with value: -0.2655033890234065.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:57:32,287] Trial 11 finished with value: -0.2659010844292459 and parameters: {'k': 41, 'hidden_layer_sizes': (100, 50), 'activation': 'tanh', 'alpha': 0.0003209296512110179, 'learning_rate_init': 0.0001068558318377528, 'batch_size': 32}. Best is trial 7 with value: -0.2655033890234065.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 13:59:35,842] Trial 12 finished with value: -0.2650772449429608 and parameters: {'k': 37, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.0011465499908929738, 'learning_rate_init': 0.00021717964398152416, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:01:33,078] Trial 13 finished with value: -0.26542637980750566 and parameters: {'k': 39, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.0015501039155157124, 'learning_rate_init': 0.0020906306080580783, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:02:43,461] Trial 14 finished with value: -0.2652114356785462 and parameters: {'k': 38, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.002504943823060327, 'learning_rate_init': 0.0022355152876588984, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:04:12,508] Trial 15 finished with value: -0.26562822293388955 and parameters: {'k': 38, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.005970581932472359, 'learning_rate_init': 0.0016260019213485569, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:04:56,438] Trial 16 finished with value: -0.266548718024113 and parameters: {'k': 45, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.007840989285898747, 'learning_rate_init': 0.0069305083870706795, 'batch_size': 128}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:06:03,232] Trial 17 finished with value: -0.2696754517012247 and parameters: {'k': 10, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.0029451565683462195, 'learning_rate_init': 0.0028999948433383414, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:08:00,467] Trial 18 finished with value: -0.2652562332105886 and parameters: {'k': 33, 'hidden_layer_sizes': (100,), 'activation': 'tanh', 'alpha': 0.00047753703891861144, 'learning_rate_init': 0.0014200966677614141, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\stefa\\miniconda3\\Lib\\site-packages\\optuna\\distributions.py:502: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50, 25) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2026-01-28 14:09:26,172] Trial 19 finished with value: -0.2664768258481644 and parameters: {'k': 35, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.015541722406211066, 'learning_rate_init': 0.0006903272799371218, 'batch_size': 32}. Best is trial 12 with value: -0.2650772449429608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés :\n",
      "{'k': 37, 'hidden_layer_sizes': (50,), 'activation': 'tanh', 'alpha': 0.0011465499908929738, 'learning_rate_init': 0.00021717964398152416, 'batch_size': 32}\n",
      "Meilleur score (neg_log_loss) : -0.2650772449429608\n",
      "Features sélectionnées : 37 (sur 45 disponibles après nettoyage)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "groups = df_train[\"gameId\"]\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    max_cols = X_train.shape[1]\n",
    "    k_value = trial.suggest_int('k', 10, max_cols)\n",
    "\n",
    "    layer_options = [(50,), (100,), (50, 25), (100, 50), (100, 50, 25)]\n",
    "    selected_index = trial.suggest_categorical('hidden_layer_index', range(len(layer_options)))\n",
    "    hidden_layers = layer_options[selected_index]    \n",
    "    \n",
    "    mlp_params = {\n",
    "        'hidden_layer_sizes': hidden_layers,\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'tanh']),\n",
    "        'solver': 'adam', # 'adam' est généralement le meilleur choix par défaut\n",
    "        'alpha': trial.suggest_float('alpha', 1e-5, 1e-1, log=True), # Régularisation L2 (échelle log)\n",
    "        'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [32, 64, 128, 'auto']),\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('cleanup', VarianceThreshold(threshold=0)), \n",
    "        ('scaler', StandardScaler()),                \n",
    "        ('selection', SelectKBest(score_func=f_classif, k=k_value)),\n",
    "        ('clf', MLPClassifier(\n",
    "            **mlp_params, \n",
    "            max_iter=300,        \n",
    "            early_stopping=True, \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # 4. Validation Croisée\n",
    "    scores = cross_val_score(\n",
    "        pipeline, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        groups=groups, \n",
    "        cv=cv, \n",
    "        scoring=\"neg_log_loss\",\n",
    "        n_jobs=1 \n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20) \n",
    "\n",
    "print(\"Meilleurs paramètres trouvés :\")\n",
    "print(study.best_params)\n",
    "print(f\"Meilleur score (neg_log_loss) : {study.best_value}\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_k = best_params.pop('k') \n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('cleanup', VarianceThreshold(threshold=0)),\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('selection', SelectKBest(score_func=f_classif, k=best_k)),\n",
    "    ('clf', MLPClassifier(\n",
    "        **best_params, \n",
    "        solver='adam',       \n",
    "        max_iter=300, \n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "n_features_in = final_pipeline.named_steps['selection'].n_features_in_\n",
    "n_features_out = best_k\n",
    "print(f\"Features sélectionnées : {n_features_out} (sur {n_features_in} disponibles après nettoyage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc134b-f6b1-4e83-a709-17102b4e6492",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model (clustering method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfaa1d-9968-4235-a188-0fda92f23804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b042d46-62d6-4c63-85b3-fc1ec7b20e95",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f628ece-a019-401c-9696-db51c478618c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f575235d-3214-40f6-b909-6212935e8225",
   "metadata": {},
   "source": [
    "# Model Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b97885c-438d-45e4-ada2-b8afa4e4a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proba\n",
    "pos_idx_rf  = np.where(rf.classes_  == 1)[0][0]\n",
    "pos_idx_mlp = np.where(mlp.classes_ == 1)[0][0]\n",
    "pos_idx_gmm = np.where(gmm.classes_ == 1)[0][0]\n",
    "pos_idx_svm = np.where(svm.classes_ == 1)[0][0]\n",
    "\n",
    "proba_rf  = rf.predict_proba(X_val_rf)[:,  pos_idx_rf]\n",
    "proba_mlp = mlp.predict_proba(X_val_mlp)[:,  pos_idx_mlp]\n",
    "proba_gmm  = gmm.predict_proba(X_val_)[:,  pos_idx_gmm]\n",
    "proba_svm  = svm.predict_proba(X_val_)[:,  pos_idx_svm]\n",
    "\n",
    "# ROC-AUC\n",
    "fpr_rf,  tpr_rf,  _ = roc_curve(y_val_rf, proba_rf)\n",
    "auc_rf = roc_auc_score(y_val_rf, proba_rf)\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_val_mlp, proba_mlp)\n",
    "auc_mlp = roc_auc_score(y_val_mlp, proba_mlp)\n",
    "fpr_gmm, tpr_gmm, _ = roc_curve(y_val_gmm, proba_gmm)\n",
    "auc_gmm = roc_auc_score(y_val_gmm, proba_gmm)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_val_svm, proba_svm)\n",
    "auc_svm = roc_auc_score(y_val_svm, proba_svm)\n",
    "\n",
    "\n",
    "plt.plot(fpr_rf,  tpr_rf,  label=f\"Random Forest (AUC={auc_rf:.3f})\")\n",
    "plt.plot(fpr_mlp,  tpr_mlp,  label=f\"Multilayer Percerton (AUC={auc_mlp:.3f})\")\n",
    "plt.plot(fpr_gmm,  tpr_gmm,  label=f\"Gaussian Mixture Model (AUC={auc_gmm:.3f})\")\n",
    "plt.plot(fpr_svm,  tpr_svm,  label=f\"Support Vector Machines (AUC={auc_svm:.3f})\")\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random 50% (AUC=0.500)\")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC - AUC\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984dfef-010e-4607-885f-1070353b1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_distance_angle, goal_rate_distance_angle = goal_rate_by_percentile(y_val_distance_angle, proba_distance_angle, step=5)\n",
    "goal_rate_percent_distance_angle = 100.0 * goal_rate_distance_angle\n",
    "\n",
    "x_all, goal_rate_all = goal_rate_by_percentile(y_val_all, proba_all, step=5)\n",
    "goal_rate_percent_all = 100.0 * goal_rate_all\n",
    "\n",
    "x_top15, goal_rate_top15 = goal_rate_by_percentile(y_val_all, proba_top15, step=5)\n",
    "goal_rate_percent_top15 = 100.0 * goal_rate_top15\n",
    "\n",
    "plt.plot(x_distance_angle,  goal_rate_percent_distance_angle,  label=\"Baseline\")\n",
    "plt.plot(x_all, goal_rate_percent_all, label=\"All features\")\n",
    "plt.plot(x_top15, goal_rate_percent_top15, label=\"Top 15\")\n",
    "\n",
    "plt.title(\"Goal Rate\")\n",
    "plt.xlabel(\"Shot probability model percentile\")\n",
    "plt.ylabel(\"Goals / (Shots + Goals)\")\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.xlim(100, 0)\n",
    "plt.xticks(np.arange(0, 101, 10))\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "ift6758-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
